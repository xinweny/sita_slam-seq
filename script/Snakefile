#### Packages ####
import glob, os
import pandas as pd

#### Functions ####
def get_organism(gse):
    metadata_df = pd.read_csv(f"{PREFIX}/SraRunTable_{gse}.txt", header=0, sep=',')

    return metadata_df['Organism'][0]

#### Config ####
workdir: "/rds/project/rs2099/rds-rs2099-toxgenomics/sita_slam-seq/"
localrules: all

PREFIX = f"data/{config['GSE']}"

SAMPLES = [os.path.basename(sample).replace('.fq.gz', '') for sample in glob.glob(f"{PREFIX}/fastq/*.fq.gz")
           if not "trimmed" in os.path.basename(sample)]
ORGANISM = get_organism(config['GSE'])

if ORGANISM == "Homo sapiens":
    FASTA = "/rds/project/rs2099/rds-rs2099-toxgenomics/shared/human/GRCh38.primary_assembly.genome.fa"
    BED_UTR = "/rds/project/rs2099/rds-rs2099-toxgenomics/shared/human/GRCh38_gencode.v34_3UTR.bed"
elif ORGANISM == "Mus musculus":
    FASTA = "/rds/project/rs2099/rds-rs2099-toxgenomics/shared/mouse/GRCm38.primary_assembly.genome.fa"
    BED_UTR = "/rds/project/rs2099/rds-rs2099-toxgenomics/shared/mouse/GRCm38_gencode.vM25_3UTR.bed"

#### Workflow ####
rule all:
    input:
        expand(f"{PREFIX}/out/count/{{sample}}_trimmed.fq_slamdunk_mapped_filtered_tcount.csv", sample=SAMPLES)

rule trim_galore:
    input:
        expand(f"{PREFIX}/fastq/{{sample}}.fq.gz", sample=SAMPLES)
    output:
        expand(f"{PREFIX}/fastq/{{sample}}_trimmed.fq.gz", sample=SAMPLES)
    params:
        job_name = f"{config['GSE']}_TRIM"
    resources:
        time_min = 120,
        nodes = 1,
        tasks = 1,
        cpus = len(SAMPLES) if len(SAMPLES) < 32 else 32
    shell:
        "trim_galore -j {resources.cpus} -o fastq --stringency 3 {input}"

rule slam_dunk:
    input:
        expand(f"{PREFIX}/fastq/{{sample}}_trimmed.fq.gz", sample=SAMPLES)
    output:
        expand(f"{PREFIX}/out/map/{{sample}}_trimmed.fq_slamdunk_mapped.bam", sample=SAMPLES),
        expand(f"{PREFIX}/out/filter/{{sample}}_trimmed.fq_slamdunk_mapped_filtered.bam", sample=SAMPLES),
        expand(f"{PREFIX}/out/snp/{{sample}}_trimmed.fq_slamdunk_mapped_filtered_snp.vcf", sample=SAMPLES),
        expand(f"{PREFIX}/out/count/{{sample}}_trimmed.fq_slamdunk_mapped_filtered_tcount.csv", sample=SAMPLES)
    resources:
        time_min = 360,
        nodes = 1,
        tasks = 1,
        cpus = len(SAMPLES) if len(SAMPLES) < 32 else 32
    params:
        job_name = f"{config['GSE']}_SLAMDUNK",
        fasta = FASTA,
        bed_utr = BED_UTR
    conda:
        "envs/slam-seq.yml"
    shell:
        f"""slamdunk all \
        -r {{params.fasta}} \
        -b {{params.bed_utr}} \
        -n 100 -m \
        -5 12 \
        -c 2 \
        -mv 0.2 \
        -mbq 27 \
        -o {PREFIX}/out \
        -t {{resources.cpus}} \
        {{input}}"""

# rule alleyoop_collapse:
#     input:
#         "out/count/{sample}_trimmed.fq_slamdunk_mapped_filtered_tcount.csv"
#     output:
#         "out/count/{sample}_trimmed.fq_slamdunk_mapped_filtered_tcount_collapsed.csv"
#     shell:
#         "singularity exec ../slamdunk.simg alleyoop collapse -o out/count {input}"
