#### Packages ####
import glob, os
import pandas as pd

#### Functions ####
def get_organism(gse):
    metadata_df = pd.read_csv(f"{PREFIX}/SraRunTable_{gse}.txt", header=0, sep=',')

    return metadata_df['Organism'][0]

#### Config ####
workdir: "/rds/project/rs2099/rds-rs2099-toxgenomics/sita_slam-seq/"
localrules: all, alleyoop_collapse, make_count_tables

PREFIX = f"data/{config['GSE']}"

SAMPLES = [os.path.basename(sample).replace('.fq.gz', '') for sample in glob.glob(f"{PREFIX}/fastq/*.fq.gz")
           if not "trimmed" in os.path.basename(sample)]
ORGANISM = get_organism(config['GSE'])

if ORGANISM == "Homo sapiens":
    FASTA = "/rds/project/rs2099/rds-rs2099-toxgenomics/shared/human/GRCh38.primary_assembly.genome.fa"
    BED_UTR = "/rds/project/rs2099/rds-rs2099-toxgenomics/shared/human/GRCh38_gencode.v34_3UTR.bed"
elif ORGANISM == "Mus musculus":
    FASTA = "/rds/project/rs2099/rds-rs2099-toxgenomics/shared/mouse/GRCm38.primary_assembly.genome.fa"
    BED_UTR = "/rds/project/rs2099/rds-rs2099-toxgenomics/shared/mouse/GRCm38_gencode.vM25_3UTR.bed"

#### Workflow ####
rule all:
    input:
        total = f"{PREFIX}/out/processed/{config['GSE']}_counts_total.txt",
        nascent = f"{PREFIX}/out/processed/{config['GSE']}_counts_nascent.txt"

rule trim_galore:
    input:
        expand(f"{PREFIX}/fastq/{{sample}}.fq.gz", sample=SAMPLES)
    output:
        expand(f"{PREFIX}/fastq/{{sample}}_trimmed.fq.gz", sample=SAMPLES)
    params:
        job_name = f"{config['GSE']}_TRIM"
    resources:
        time_min = 120,
        nodes = 1,
        tasks = 1,
        cpus = len(SAMPLES) if len(SAMPLES) < 32 else 32
    shell:
        "trim_galore -j {resources.cpus} -o fastq --stringency 3 {input}"

rule slam_dunk:
    input:
        expand(f"{PREFIX}/fastq/{{sample}}_trimmed.fq.gz", sample=SAMPLES)
    output:
        expand(f"{PREFIX}/out/map/{{sample}}_trimmed.fq_slamdunk_mapped.bam", sample=SAMPLES),
        expand(f"{PREFIX}/out/filter/{{sample}}_trimmed.fq_slamdunk_mapped_filtered.bam", sample=SAMPLES),
        expand(f"{PREFIX}/out/snp/{{sample}}_trimmed.fq_slamdunk_mapped_filtered_snp.vcf", sample=SAMPLES),
        expand(f"{PREFIX}/out/count/{{sample}}_trimmed.fq_slamdunk_mapped_filtered_tcount.tsv", sample=SAMPLES)
    resources:
        time_min = 360,
        nodes = 1,
        tasks = 1,
        cpus = len(SAMPLES) if len(SAMPLES) < 32 else 32
    params:
        job_name = f"{config['GSE']}_SLAMDUNK",
        fasta = FASTA,
        bed_utr = BED_UTR
    conda:
        "envs/slam-seq.yml"
    shell:
        f"""slamdunk all \
        -r {{params.fasta}} \
        -b {{params.bed_utr}} \
        -n 100 -m \
        -5 12 \
        -c 2 \
        -rl 100 \
        -mv 0.2 \
        -mbq 27 \
        -o {PREFIX}/out \
        -t {{resources.cpus}} \
        {{input}}"""

rule alleyoop_collapse:
    input:
        expand(f"{PREFIX}/out/count/{{sample}}_trimmed.fq_slamdunk_mapped_filtered_tcount.tsv", sample=SAMPLES)
    output:
        expand(f"{PREFIX}/out/count/{{sample}}.csv", sample=SAMPLES)
    run:
        for sample in input:
            shell(f"alleyoop collapse -o {PREFIX}/out/count {sample}")

            collapse_out = sample.replace('.tsv', '_collapsed.csv')
            shell(f"mv {collapse_out} {collapse_out.replace('_trimmed.fq_slamdunk_mapped_filtered_tcount_collapsed', '')}")

rule make_count_tables:
    input:
        expand(f"{PREFIX}/out/count/{{sample}}.csv", sample=SAMPLES)
    output:
        total = f"{PREFIX}/out/processed/{config['GSE']}_counts_total.txt",
        nascent = f"{PREFIX}/out/processed/{config['GSE']}_counts_nascent.txt"
    run:
        shell("module load libxml2-2.9.8-gcc-5.4.0-sy2r4k7")
        shell("module load r-4.0.2-gcc-5.4.0-xyx46xb")

        shell(f"Rscript /home/xwy21/project/sita_slam-seq/script/create_count_matrix.R \
        -c {PREFIX}/out/count \
        -g {config['GSE']}")
